"""
ðŸ”µ langchain_managerã®å½¹å‰²
    AIã¨ã®é€£æº(ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å…¥åŠ›æ¸¡ã™ã“ã¨ã‹ã‚‰ã€AIã®è¿”ç­”è¿”ã™ã¾ã§)
    chat_managerã‹ã‚‰å—ã‘å–ã£ãŸãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å…¥åŠ›ã‚’AIã«æ¸¡ã™
    AIã®å›žç­”ã‚’å–å¾—
    AIã®å›žç­”ã‚’chat_managerã«è¿”ã™
    ä¼šè©±å†…å®¹ã‹ã‚‰ã‚¿ã‚¤ãƒˆãƒ«ã‚’ç”Ÿæˆ
    
ã€æ›´æ–°å±¥æ­´ã€‘
- RAGãƒ¢ãƒ¼ãƒ‰ç”¨ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã¨ãƒ¬ã‚¹ãƒãƒ³ã‚¹ç”Ÿæˆã‚’è¿½åŠ 
"""
# LangChainã®OpenAIæŽ¥ç¶šã‚¯ãƒ©ã‚¹
from langchain_openai import ChatOpenAI
# ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç®¡ç†
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
# å‡ºåŠ›ã‚’æ–‡å­—åˆ—ã«å¤‰æ›
from langchain_core.output_parsers import StrOutputParser
# ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸åž‹
from langchain_core.messages import HumanMessage, AIMessage, SystemMessage
# åž‹ãƒ’ãƒ³ãƒˆç”¨
from typing import List, Generator

from config.settings import OPENAI_MODEL, TEMPERATURE, TITLE_MAX_LENGTH, SYSTEM_PROMPT_NORMAL, SYSTEM_PROMPT_RAG, SYSTEM_PROMPT_TITLE

class LangChainManager:
    """
    LangChainã‚’ä½¿ã£ãŸAIé€£æºã‚’ç®¡ç†ã™ã‚‹ã‚¯ãƒ©ã‚¹
    åˆæœŸåŒ–ã—ãŸæ™‚ã«å¼•æ•°ã‚’ä¸Žãˆã¦ã„ãªã„ã‹ã‚‰ã€model,temperatureã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå¼•æ•°ãŒé©ç”¨ã•ã‚Œã‚‹
    """
    def __init__(self, model: str = OPENAI_MODEL, temperature: float = TEMPERATURE):
        """
        OpenAIã¨ã®é€£æºã‚’è¨­å®šã™ã‚‹
            
        ã€åˆæœŸåŒ–ã§è¡Œã†ã“ã¨ã€‘
        1. ãƒ¢ãƒ‡ãƒ«ã¨æ¸©åº¦ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’è¨­å®š
        2. ChatOpenAIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’ä½œæˆ
        3. ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’æº–å‚™
        4. å¿œç­”ãƒã‚§ãƒ¼ãƒ³ã‚’æ§‹ç¯‰
            
        Args:
            model: ä½¿ç”¨ã™ã‚‹OpenAIãƒ¢ãƒ‡ãƒ«å
            temperature: å¿œç­”ã®å¤šæ§˜æ€§ï¼ˆ0.0ã€œ1.0ï¼‰
        """
        self.model = model
        self.temperature = temperature

        # é–¢æ•°åã®é ­ã«ã¤ãã€Œ_ã€ã¯ãã®ã‚¯ãƒ©ã‚¹å†…ã‹ã‚‰ã—ã‹å‘¼ã³å‡ºã•ã‚Œãªã„ã“ã¨ã‚’è¡¨ã™ãƒžãƒŠãƒ¼(ãƒ«ãƒ¼ãƒ«ã§ã¯ãªã„)
        # 2._initialize_llm() ã‚’å‘¼ã³å‡ºã—ã¦LLMã‚’åˆæœŸåŒ–
        self.llm = self._initialize_llm()
        # â†’ ChatOpenAI(model="gpt-4o-mini", temperature=0.7) ãŒå®Ÿè¡Œã•ã‚Œã‚‹
        # â†’ OpenAIã«æŽ¥ç¶šã§ãã‚‹çŠ¶æ…‹ã«ãªã‚‹

        # 3. ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’ä½œæˆ
        self.prompt = self._create_prompt()
        # â†’ ChatPromptTemplate.from_messages([...]) ãŒå®Ÿè¡Œã•ã‚Œã‚‹
        # â†’ ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã¨MessagesPlaceholderãŒè¨­å®šã•ã‚Œã‚‹

        # 4. å‡ºåŠ›ãƒ‘ãƒ¼ã‚µãƒ¼ã‚’åˆæœŸåŒ–(AIã®å¿œç­”ã‚’æ–‡å­—åˆ—ã«å¤‰æ›ã™ã‚‹ãŸã‚ã®ã‚‚ã®)
        self.output_parser = StrOutputParser()
        # 5. ã“ã‚Œã‚‰ã‚’çµ„ã¿åˆã‚ã›ã¦ãƒã‚§ãƒ¼ãƒ³ã‚’ä½œæˆ(prompt â†’ llm â†’ output_parser ã®é †ã§å‡¦ç†ãŒæµã‚Œã‚‹)
        # |(ãƒ‘ã‚¤ãƒ—)æ¼”ç®—å­ã§ã¤ãªãã“ã¨ã§ã€ãƒ‡ãƒ¼ã‚¿ãŒé †ç•ªã«æµã‚Œã¦ã„ã
        self.chain = self.prompt | self.llm | self.output_parser
        
        # ã‚¿ã‚¤ãƒˆãƒ«ç”Ÿæˆç”¨ã®ãƒã‚§ãƒ¼ãƒ³ã‚‚ä½œæˆ
        self.title_prompt = self._create_title_prompt()
        self.title_chain = self.title_prompt | self.llm | self.output_parser
        
        # ðŸ†• RAGç”¨ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã¨ãƒã‚§ãƒ¼ãƒ³ã‚’ä½œæˆ
        self.rag_prompt = self._create_rag_prompt()
        self.rag_chain = self.rag_prompt | self.llm | self.output_parser
    
    def _initialize_llm(self) -> ChatOpenAI:
        """
        LLM(Large Language Model)ã®åˆæœŸåŒ–

        Returns:
        ChatOpenAIã®ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹(AIã¨ã®æŽ¥ç¶šã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ)
        
        ã€è£œè¶³ã€‘
        -> ChatOpenAI ã¯ã€Œã“ã®é–¢æ•°ã®æˆ»ã‚Šå€¤ã®åž‹ã€ã‚’ç¤ºã™åž‹ãƒ’ãƒ³ãƒˆ
        å®Ÿéš›ã®å‹•ä½œã«ã¯å½±éŸ¿ã—ãªã„ãŒã€ã‚³ãƒ¼ãƒ‰ã‚’èª­ã‚€äººã«åˆ†ã‹ã‚Šã‚„ã™ãã™ã‚‹ãŸã‚
        """
        return ChatOpenAI(
            model=self.model,
            temperature=self.temperature
        )
    
    def _create_prompt(self) -> ChatPromptTemplate:
        # ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹åŒ–ã—ãŸChatPromptTemplateã‚’è¿”ã™ã€Œã ã‘ã€
        # ã‚¯ãƒ©ã‚¹ã®ä¸­ã«é–¢æ•°ãŒã‚ã‚‹      
        """
        ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã®ä½œæˆ

        Returns:
        ChatPromptTemplateã®ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
        """

        return ChatPromptTemplate.from_messages([
            ("system", SYSTEM_PROMPT_NORMAL),
            MessagesPlaceholder(variable_name="messages")
        ])
    
    def _create_title_prompt(self) -> ChatPromptTemplate:
        """
        ã‚¿ã‚¤ãƒˆãƒ«ç”Ÿæˆç”¨ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’ä½œæˆ
        
        Returns:
        ChatPromptTemplateã®ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
        """

        return ChatPromptTemplate.from_messages([
            ("system", SYSTEM_PROMPT_TITLE),
            MessagesPlaceholder(variable_name="messages")
        ])
    
    def _create_rag_prompt(self) -> ChatPromptTemplate:
        """
        RAGç”¨ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’ä½œæˆ
        
        Returns:
        ChatPromptTemplateã®ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
        """

        return ChatPromptTemplate.from_messages([
            ("system", SYSTEM_PROMPT_RAG),
            MessagesPlaceholder(variable_name="messages")
        ])
    
    def create_human_message(self, content: str) -> HumanMessage:
        """
        ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å…¥åŠ›ã‹ã‚‰HumanMessageã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’ä½œæˆ
        
        Args:
            content: ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å…¥åŠ›ãƒ†ã‚­ã‚¹ãƒˆ(ä¾‹: "ã“ã‚“ã«ã¡ã¯")
        
        Returns:
            HumanMessage: LangChainç”¨ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ

        """
        return HumanMessage(content=content)
    
    def create_ai_message(self, content: str) -> AIMessage:
        """
        AIã®å¿œç­”ã‹ã‚‰AIMessageã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’ä½œæˆ
        
        Args:
            content: AIã®å¿œç­”ãƒ†ã‚­ã‚¹ãƒˆ(ä¾‹: "ã“ã‚“ã«ã¡ã¯!èª¿å­ã¯ã©ã†?")
        
        Returns:
            AIMessage: LangChainç”¨ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ

        """
        # AIMessageã‚¯ãƒ©ã‚¹ã‚’ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹åŒ–
        # contentã‚’å¼•æ•°ã¨ã—ã¦æ¸¡ã™ã¨ã€AIã®å¿œç­”ã¨ã—ã¦æ‰±ã‚ã‚Œã‚‹
        return AIMessage(content=content)
    
    def get_streaming_response(
        self,
        messages: List
    ) -> Generator[str, None, None]:
        """
        ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å±¥æ­´ã‚’åŸºã«AIã‹ã‚‰ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å¿œç­”ã‚’å–å¾—
        
        Args:
            messages: LangChainå½¢å¼ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å±¥æ­´ãƒªã‚¹ãƒˆ
                [HumanMessage(...), AIMessage(...), ...]
        """
        for chunk in self.chain.stream({"messages": messages}):
            yield chunk
    
    def get_streaming_response_rag(
        self,
        messages: List
    ) -> Generator[str, None, None]:
        """
        ðŸ†• RAGãƒ¢ãƒ¼ãƒ‰ç”¨ã®ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å¿œç­”ã‚’å–å¾—
        
        Args:
            messages: LangChainå½¢å¼ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å±¥æ­´ãƒªã‚¹ãƒˆ
                      ï¼ˆRAGãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’å«ã‚€ï¼‰
        
        Yields:
            str: AIã‹ã‚‰ã®å¿œç­”ãƒãƒ£ãƒ³ã‚¯
        """
        for chunk in self.rag_chain.stream({"messages": messages}):
            yield chunk
    
    def get_complete_response(
        self,
        messages: List
    ) -> str:
        """
        ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å±¥æ­´ã‚’åŸºã«AIã‹ã‚‰å®Œå…¨ãªå¿œç­”ã‚’å–å¾—
        (ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ã§ã¯ãªãä¸€åº¦ã«å–å¾—)
        
        Args:
            messages: LangChainå½¢å¼ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å±¥æ­´ãƒªã‚¹ãƒˆ
        
        Returns:
            str: AIã‹ã‚‰ã®å®Œå…¨ãªå¿œç­”(ä¾‹: "ã“ã‚“ã«ã¡ã¯!èª¿å­ã¯ã©ã†?")
        
        ã€get_streaming_response()ã¨ã®é•ã„ã€‘
        - get_streaming_response: 1æ–‡å­—ãšã¤è¿”ã™(ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ è¡¨ç¤ºå‘ã‘)
        - get_complete_response: å…¨æ–‡ã‚’ä¸€æ°—ã«è¿”ã™(ãƒãƒƒãƒå‡¦ç†å‘ã‘)
        """
        return self.chain.invoke({"messages": messages})
    
    def generate_title(self, messages: List) -> str:
        """
        ä¼šè©±å†…å®¹ã‹ã‚‰ã‚¿ã‚¤ãƒˆãƒ«ã‚’ç”Ÿæˆ
        
        Args:
            messages: LangChainå½¢å¼ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å±¥æ­´ãƒªã‚¹ãƒˆ(æœ€åˆã®æ•°ä»¶)
        
        Returns:
            ç”Ÿæˆã•ã‚ŒãŸã‚¿ã‚¤ãƒˆãƒ«(15æ–‡å­—ä»¥å†…)
        """
        # ã‚¿ã‚¤ãƒˆãƒ«ç”Ÿæˆãƒã‚§ãƒ¼ãƒ³ã‚’å®Ÿè¡Œ
        title = self.title_chain.invoke({"messages": messages})
        
        # ä½™è¨ˆãªç©ºç™½ã‚„æ”¹è¡Œã‚’å‰Šé™¤
        title = title.strip()

        if len(title) > TITLE_MAX_LENGTH:
            title = title[:TITLE_MAX_LENGTH]
        
        return title