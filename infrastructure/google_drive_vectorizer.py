"""
infrastructure/google_drive_vectorizer.py
Google Driveä¸Šã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç›´æ¥ãƒ¡ãƒ¢ãƒªä¸Šã§å‡¦ç†ã—ã€ChromaDBã¸ãƒ™ã‚¯ãƒˆãƒ«åŒ–ã™ã‚‹ã‚¯ãƒ©ã‚¹
"""
import os
import logging
from typing import List, Optional, Dict, Any
from pathlib import Path

# Google & LangChain Imports
from langchain_google_community import GoogleDriveLoader
from langchain_community.document_loaders import UnstructuredFileIOLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_openai import OpenAIEmbeddings
from langchain_chroma import Chroma
from langchain_core.documents import Document

# æ—¢å­˜ã®è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿
from config.settings import (
    CHROMA_DB_PATH, 
    COLLECTION_NAME, 
    CHUNK_SIZE, 
    CHUNK_OVERLAP,
    EMBEDDING_MODEL
)

# ãƒ­ã‚°è¨­å®š
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class GoogleDriveVectorizer:
    """
    Google Drive â†’ ChromaDB ãƒ™ã‚¯ãƒˆãƒ«åŒ–ã‚¨ãƒ³ã‚¸ãƒ³
    """
    
    def __init__(
        self,
        credentials_path: str = "credentials.json",
        token_path: str = "google_token.json",
        persist_directory: str = CHROMA_DB_PATH,
        collection_name: str = COLLECTION_NAME
    ):
        self.credentials_path = Path(credentials_path)
        self.token_path = Path(token_path)
        self.persist_directory = persist_directory
        self.collection_name = collection_name
        
        # Embeddingsãƒ¢ãƒ‡ãƒ«ã®åˆæœŸåŒ–
        self.embeddings = OpenAIEmbeddings(model=EMBEDDING_MODEL)
        
        # Text Splitterã®åˆæœŸåŒ– (æ—¥æœ¬èªã«å¼·ã„åŒºåˆ‡ã‚Šæ–‡å­—è¨­å®š)
        self.text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=CHUNK_SIZE,
            chunk_overlap=CHUNK_OVERLAP,
            length_function=len,
            separators=["\n\n", "\n", "ã€‚", "ã€", " ", ""]
        )

    def _create_extension_filter(self):
        """æ‹¡å¼µå­ã«ã‚ˆã‚‹ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°é–¢æ•°ã‚’ç”Ÿæˆ"""
        # è¨±å¯ã™ã‚‹æ‹¡å¼µå­
        ALLOWED_EXTENSIONS = {".pdf", ".docx", ".txt", ".md", ".csv", ".html"}
        
        def extension_filter(search: Dict[str, Any], file: Dict[str, Any]) -> bool:
            mime_type = file.get("mimeType", "")
            file_name = file.get("name", "")
            
            # Google Docsãªã©ã¯é€šã™
            if mime_type.startswith("application/vnd.google-apps"):
                return True
            
            # æ‹¡å¼µå­ãƒã‚§ãƒƒã‚¯
            ext = Path(file_name).suffix.lower()
            return ext in ALLOWED_EXTENSIONS
            
        return extension_filter

    def process_folder(
        self,
        folder_id: str,
        recursive: bool = True
    ) -> bool:
        """
        æŒ‡å®šãƒ•ã‚©ãƒ«ãƒ€å†…ã®å…¨ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‡¦ç†ã—ã¦ChromaDBã«æ ¼ç´
        """
        if not self.credentials_path.exists():
            logger.error(f"âŒ èªè¨¼ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {self.credentials_path}")
            return False

        logger.info(f"ğŸ“‚ Google Driveãƒ•ã‚©ãƒ«ãƒ€èª­ã¿è¾¼ã¿é–‹å§‹ (ID: {folder_id})")
        
        try:
            # 1. Google Drive Loaderã®è¨­å®š
            # UnstructuredFileIOLoaderã‚’ä½¿ã†ã“ã¨ã§ã€PDFãªã©ã®ãƒã‚¤ãƒŠãƒªã‚‚ãƒ¡ãƒ¢ãƒªä¸Šã§å‡¦ç†å¯èƒ½
            loader = GoogleDriveLoader(
                folder_id=folder_id,
                credentials_path=str(self.credentials_path),
                token_path=str(self.token_path),
                recursive=recursive,
                file_types=["document", "sheet", "slide", "pdf"], # Googleå½¢å¼ + PDF
                file_loader_cls=UnstructuredFileIOLoader, # ãƒã‚¤ãƒŠãƒªå‡¦ç†ç”¨ãƒ­ãƒ¼ãƒ€ãƒ¼
                file_loader_kwargs={"mode": "elements"},
                filter=self._create_extension_filter() # æ‹¡å¼µå­ãƒ•ã‚£ãƒ«ã‚¿é©ç”¨
            )

            # 2. ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆèª­ã¿è¾¼ã¿
            documents = loader.load()
            if not documents:
                logger.warning("âš ï¸ èª­ã¿è¾¼ã‚ã‚‹ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆãŒã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
                return False
                
            logger.info(f"ğŸ“„ {len(documents)} ä»¶ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸã€‚ãƒãƒ£ãƒ³ã‚¯åˆ†å‰²ã‚’é–‹å§‹ã—ã¾ã™...")

            # 3. ãƒãƒ£ãƒ³ã‚¯åˆ†å‰²
            chunks = self.text_splitter.split_documents(documents)
            logger.info(f"ğŸ§© {len(chunks)} å€‹ã®ãƒãƒ£ãƒ³ã‚¯ã‚’ä½œæˆã—ã¾ã—ãŸã€‚")

            # 4. ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã®èª¿æ•´ï¼ˆã‚½ãƒ¼ã‚¹ãƒ‘ã‚¹ãªã©ã‚’ãã‚Œã„ã«ï¼‰
            for doc in chunks:
                # ã‚½ãƒ¼ã‚¹å…ƒãŒã‚ã‹ã‚‹ã‚ˆã†ã«ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’æ•´ç†
                if 'source' in doc.metadata:
                    doc.metadata['source'] = Path(doc.metadata['source']).name

            # 5. ChromaDBã¸ä¿å­˜ï¼ˆæ—¢å­˜ã®ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ãŒã‚ã‚Œã°è¿½è¨˜ã€ãªã‘ã‚Œã°ä½œæˆï¼‰
            # langchain_chroma.Chroma ã‚’ä½¿ç”¨ã—ã¦ä¿å­˜
            Chroma.from_documents(
                documents=chunks,
                embedding=self.embeddings,
                persist_directory=self.persist_directory,
                collection_name=self.collection_name
            )
            
            logger.info(f"âœ… ãƒ™ã‚¯ãƒˆãƒ«åŒ–å®Œäº†ï¼ä¿å­˜å…ˆ: {self.persist_directory}")
            return True

        except Exception as e:
            logger.error(f"âŒ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
            import traceback
            traceback.print_exc()
            return False

    def clear_collection(self):
        """ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ã®å…¨å‰Šé™¤ï¼ˆãƒªã‚»ãƒƒãƒˆç”¨ï¼‰"""
        try:
            import chromadb
            client = chromadb.PersistentClient(path=self.persist_directory)
            client.delete_collection(self.collection_name)
            logger.info("ğŸ—‘ï¸ æ—¢å­˜ã®ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ã‚’å‰Šé™¤ã—ã¾ã—ãŸã€‚")
        except Exception as e:
            # ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ãŒãªã„å ´åˆã¯ç„¡è¦–
            logger.info("â„¹ï¸ æ–°è¦ä½œæˆã¨ã—ã¦å‡¦ç†ã—ã¾ã™ã€‚")